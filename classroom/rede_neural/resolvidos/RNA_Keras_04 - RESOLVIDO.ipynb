{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material de aula - Redes Neurais e Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <center> Laboratório 4 - Keras: Identificação de Dígitos com CNN </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#CÉLULA KE-LIB-01\n",
    "import numpy as np\n",
    "import keras as K\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação de dígitos a partir da utilização de CNN's.\n",
    "\n",
    "### Dados: 1000 imagens de treinamento e 100 imagens de teste, obtidas do dataset MNIST (modified National Institute of Standards and Technology) benchmark dataset.\n",
    "\n",
    "### O dataset completo possui 60.000 imagens de treinamento e 10.000 de teste.\n",
    "\n",
    "### Dados das imagens: 28 x 28 x 1 pixels (escala de cinza, onde 0=branco e 255=preto)\n",
    "### Dados da CNN: 784 - 32 - 64 - 10 - 10 (Entrada = 784 pixels, Saída = 10 dígitos)\n",
    "### Modelo deve ser treinado para 50 épocas\n",
    "\n",
    "### Formato do arquivo de dados é dado por 1000 linhas seguindo o padrão:\n",
    "\n",
    "### 2 ** 0 0 152 27 .. 0\n",
    "### 5 ** 0 0 38 122 .. 0\n",
    "\n",
    "### onde o primeiro numero é o digito [0 9] enquanto os demais numeros da linha são os 784 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Os valores numericos foram normalizados com operador Min-Max, os booleanos foram convertidos para [-1, 1] e os categóricos para encoding 1-of(N-1). A saída ficou 3m 0 (sem problema) e 1 (com algum problema).  Os arquivos do Data set já foram previamente processados e separados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Importando o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CÉLULA KE-LIB-02\n",
    "from keras.datasets import mnist\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "\n",
    "X_train = train_x[0:1000]\n",
    "y_train = train_y[0:1000]\n",
    "\n",
    "X_test = test_x[0:100]\n",
    "y_test = test_y[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As redes CNN do Keras esperam dados de entrada no format de array NumPy com 4 dimensões: \n",
    "### [numero de itens, largura da imagem, altura da imagem e numero de canais (1 para escala de cinza e 3 para RGB)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Faça a normalização das imagens e o hot encoding do vetor de saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CÉLULA KE-LIB-03\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_train = X_train / 255\n",
    "\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test / 255\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_train_encoded = onehot_encoder.fit_transform(y_train)\n",
    "\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_test_encoded = onehot_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Faça a inicialização randômica dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CÉLULA KE-LIB-04\n",
    "np.random.seed(4)\n",
    "tf.set_random_seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Monte o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CÉLULA KE-LIB-05\n",
    "tf.logging.set_verbosity(tf.logging.ERROR) #desliga os warnings do tensorflow\n",
    "\n",
    "#Inicializador\n",
    "init = K.initializers.glorot_uniform()\n",
    "\n",
    "#Criando o otimizador\n",
    "simple_adadelta = K.optimizers.Adadelta()\n",
    "\n",
    "#Construindo o modelo (topologia)\n",
    "model = K.models.Sequential()\n",
    "\n",
    "#Camada convolucional\n",
    "model.add(K.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1,1), padding='same', kernel_initializer=init, activation='relu', input_shape=(28,28,1)))\n",
    "\n",
    "#Camada convolucional\n",
    "model.add(K.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1,1), padding='same', kernel_initializer=init, activation='relu'))\n",
    "\n",
    "#MaxPooling\n",
    "model.add(K.layers.MaxPooling2D(pool_size=(2, 2))) \n",
    "\n",
    "#Dropout na camada anterior\n",
    "model.add(K.layers.Dropout(0.25))\n",
    "\n",
    "#Flatten para entrada da rede densa\n",
    "model.add(K.layers.Flatten())\n",
    "\n",
    "#Rede densa\n",
    "model.add(K.layers.Dense(units=100, kernel_initializer=init, activation='relu'))\n",
    "model.add(K.layers.Dropout(0.5))\n",
    "model.add(K.layers.Dense(units=10, kernel_initializer=init, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Execute o Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando treinamento... \n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9693 - acc: 0.3190\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2605 - acc: 0.5870\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8451 - acc: 0.7410\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6523 - acc: 0.8050\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4623 - acc: 0.8650\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4494 - acc: 0.8550\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3551 - acc: 0.8920\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3088 - acc: 0.9150\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2347 - acc: 0.9320\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2169 - acc: 0.9300\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1778 - acc: 0.9510\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1828 - acc: 0.9470\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1494 - acc: 0.9560\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1157 - acc: 0.9670\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1068 - acc: 0.9630\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1135 - acc: 0.9640\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0973 - acc: 0.9700\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0961 - acc: 0.9750\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0778 - acc: 0.9790\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0609 - acc: 0.9840\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0706 - acc: 0.9730\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0501 - acc: 0.9890\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0631 - acc: 0.9830\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0579 - acc: 0.9800\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0509 - acc: 0.9850\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0501 - acc: 0.9890\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0353 - acc: 0.9930\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0361 - acc: 0.9900\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0400 - acc: 0.9860\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0330 - acc: 0.9890\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0282 - acc: 0.9880\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0261 - acc: 0.9930\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0273 - acc: 0.9890\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0380 - acc: 0.9880\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0202 - acc: 0.9960\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0179 - acc: 0.9950\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0195 - acc: 0.9930\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0421 - acc: 0.9830\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0299 - acc: 0.9900\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0162 - acc: 0.9970\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0187 - acc: 0.9930\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0150 - acc: 0.9960\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0153 - acc: 0.9960\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0142 - acc: 0.9960\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0113 - acc: 0.9980\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0189 - acc: 0.9950\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0208 - acc: 0.9920\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0118 - acc: 0.9960\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0155 - acc: 0.9980\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0117 - acc: 0.9970\n",
      "Treinamento finalizado \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CÉLULA KE-LIB-06\n",
    "batch_size = 128\n",
    "max_epochs = 50\n",
    "print(\"Iniciando treinamento... \")\n",
    "h = model.fit(X_train, y_train_encoded, batch_size=batch_size, epochs=max_epochs, verbose=1)\n",
    "print(\"Treinamento finalizado \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Faça a avaliaçao do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro médio do conjunto de treinamento: Perda 0.0002, acuracia 100.0000\n",
      "Erro médio do conjunto de teste: Perda 0.0514, acuracia 98.0000\n"
     ]
    }
   ],
   "source": [
    "#CÉLULA KE-LIB-07\n",
    "eval = model.evaluate(X_train, y_train_encoded, verbose=0)\n",
    "print(\"Erro médio do conjunto de treinamento: Perda {0:.4f}, acuracia {1:.4f}\".format(eval[0], eval[1]*100))\n",
    "\n",
    "eval = model.evaluate(X_test, y_test_encoded, verbose=0)\n",
    "print(\"Erro médio do conjunto de teste: Perda {0:.4f}, acuracia {1:.4f}\".format(eval[0], eval[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Salve o modelo em Arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando modelo em arquivo \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CÉLULA KE-LIB-8\n",
    "# Salvando modelo em arquivo\n",
    "print(\"Salvando modelo em arquivo \\n\")\n",
    "mp = \".\\\\mnist_model.h5\"\n",
    "model.save(mp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - Faça um teste de operação com o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando o modelo para previsão de dígitos para a imagem: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O valor do dígito previsto é: \n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Usando o modelo para previsão de dígitos para a imagem: \")\n",
    "unknown = np.zeros(shape=(28,28), dtype=np.float32)\n",
    "for row in range(5,23): unknown[row][9] = 180 # vertical line\n",
    "for rc in range(9,19): unknown[rc][rc] = 250 # diagonal line\n",
    "plt.imshow(unknown, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()\n",
    "\n",
    "unknown = unknown.reshape(1, 28,28,1)\n",
    "predicted = model.predict(unknown)\n",
    "print(\"\\nO valor do dígito previsto é: \")\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 - Faça o pós-processamento para fornecer resposta compreensível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seis\n"
     ]
    }
   ],
   "source": [
    "# 7. Pos-processamento\n",
    "str = ['zero', 'um', 'dois', 'tres', 'quatro', 'cinco', 'seis', 'sete', 'oito', 'nove']\n",
    "\n",
    "index = np.argmax(predicted[0])\n",
    "digit = str[index]\n",
    "print(digit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
