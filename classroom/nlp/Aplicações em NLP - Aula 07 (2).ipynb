{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 align=\"center\"> Aplicações em Processamento de Linguagem Natural </h1>\n<h2 align=\"center\"> Aula 07 - Extração de Informação (Parte 2)</h2>\n<h3 align=\"center\"> Prof. Fernando Vieira da Silva MSc.</h3>"},{"metadata":{},"cell_type":"markdown","source":"<h2>1. Extração de Relacionamentos</h2>\n<p>A extração de relacionamentos consiste em identificar a ligação entre diversas entidades nomeadas no texto. Isso envolve mencionar qual é o tipo da ligação entre duas entidades. Considere o exemplo de sentença abaixo.</p>\n\n<p>\"Carlos Alberto de Nogueira é o morador mais antigo da Rua Praça da Alegria.\"</p>\n\n<p>Temos as entidades:</p>\n\n* Carlos Alberto de Nogueira (PESSOA)\n* Rua Praça da Alegria (LOCALIDADE)\n\n<p>Essas mesmas entidades estão relacionadas da seguinte forma:</p>\n\n[Carlos Alberto de Nogueira (PERSON); morador mais antigo; Rua Praça da Alegria (LOCALIDADE)]\n\n\n<p>Um dos mais famosos exemplos de sistema de reconhecimento é o [Never-Ending Language Learning (NELL)](http://rtw.ml.cmu.edu/), projeto desenvolvido pela Universidade Carnigie Mellon, com participação do Google e inclusive de pesquisadores brasileiros financiados pelo CNPq. Esse projeto consiste em extrair relacionamentos de milhões de páginas da internet, criando uma gigantesca base de conhecimento.</p>"},{"metadata":{},"cell_type":"markdown","source":"<h2>2. Métodos para identificação de relacionamentos</h2>\n\n<p>Os métodos mais comuns para identificar relacionamentos entre entidades são:</p>\n\n* **Padrões codificados manualmente**: Basta criar padrões usando expressões regulares, por exemplo, para identificar que duas entidades se relacionam. Assim como em \"X mora em Y\" pode ser um padrão para identificar o relacionamento (X, mora_em, Y) entre uma entidade X do tipo PESSOA e uma entidade Y do tipo LOCALIDADE.\n* **Métodos bootstraping**: Com poucos dados, procura por ocorrências de duas entidades em que já se conhece o relacionamento (no Google, por exemplo), e usa os modelos encontrados como modelos para o mesmo relacionamento entre outras entidades.\n* **Métodos supervisionados**: Com base num corpus anotado com relacionamentos, criar modelos que 1) detecte quando existe o relacionamento entre duas entidades e 2) classifique o tipo de relacionamento entre elas. \n\n<p>Nesta aula, vamos ver um método supervisionado para classificar o relacionamento entre entidades, usando técnicas que já utilizamos em aulas anteriores.</p>\n\n<p>Para isso, utilizaremos alguns atributos mais comuns para o problema, como:</p>\n\n* Bag of Words/LSA\n* Flags indicadores dos tipos das entidades\n* Número de palavras entre as duas entidades\n* Flag indicando se o texto de uma entidade é composto pelo texto da outra\n* POS tags\n* etc\n\n"},{"metadata":{},"cell_type":"markdown","source":"<h2>3. Criando um Modelo Supervisionado</h2>\n<p> Vamos utilizar o corpus [Figure Eight: Medical Sentence Summary](https://www.kaggle.com/kmader/figure-eight-medical-sentence-summary), que possui diversas sentenças extraídas do PubMed, com entidades anotadas, assim como seus tipos de relacionamento.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf_train = pd.read_csv('../input/figure-eight-medical-sentence-summary/train.csv')\ndf_test = pd.read_csv('../input/figure-eight-medical-sentence-summary/test.csv')\n\ndf_train.head(20)","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"     _unit_id          ...                          twrex\n0   502808352          ...                   RO-may_treat\n1   502808352          ...                   RO-may_treat\n2   502808352          ...                   RO-may_treat\n3   502808352          ...                   RO-may_treat\n4   502808352          ...                   RO-may_treat\n5   502808352          ...                   RO-may_treat\n6   502808352          ...                   RO-may_treat\n7   502808354          ...           RO-has_manifestation\n8   502808354          ...           RO-has_manifestation\n9   502808354          ...           RO-has_manifestation\n10  502808354          ...           RO-has_manifestation\n11  502808354          ...           RO-has_manifestation\n12  502808354          ...           RO-has_manifestation\n13  502808354          ...           RO-has_manifestation\n14  502808355          ...                    RO-cause_of\n15  502808355          ...                    RO-cause_of\n16  502808355          ...                    RO-cause_of\n17  502808355          ...                    RO-cause_of\n18  502808355          ...                    RO-cause_of\n19  502808355          ...                    RO-cause_of\n\n[20 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_unit_id</th>\n      <th>_created_at</th>\n      <th>_canary</th>\n      <th>_id</th>\n      <th>_started_at</th>\n      <th>_channel</th>\n      <th>_trust</th>\n      <th>_worker_id</th>\n      <th>_country</th>\n      <th>_region</th>\n      <th>_city</th>\n      <th>_ip</th>\n      <th>direction</th>\n      <th>b1</th>\n      <th>b2</th>\n      <th>direction_gold</th>\n      <th>e1</th>\n      <th>e2</th>\n      <th>relation</th>\n      <th>relex_relcos</th>\n      <th>sent_id</th>\n      <th>sentence</th>\n      <th>term1</th>\n      <th>term2</th>\n      <th>twrex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>502808352</td>\n      <td>7/13/2014 13:48:35</td>\n      <td>NaN</td>\n      <td>1321892767</td>\n      <td>7/13/2014 13:48:14</td>\n      <td>clixsense</td>\n      <td>0.9167</td>\n      <td>27871219</td>\n      <td>NLD</td>\n      <td>07</td>\n      <td>Amsterdam</td>\n      <td>87.210.207.223</td>\n      <td>IM CEFTRIAXONE treats URETHRAL OR RECTAL GONOR...</td>\n      <td>41</td>\n      <td>128</td>\n      <td>NaN</td>\n      <td>69</td>\n      <td>142</td>\n      <td>treats</td>\n      <td>1.000000</td>\n      <td>907845-FS1-2</td>\n      <td>For treatment of uncomplicated cervical, URETH...</td>\n      <td>URETHRAL OR RECTAL GONORRHEA</td>\n      <td>IM CEFTRIAXONE</td>\n      <td>RO-may_treat</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>502808352</td>\n      <td>7/13/2014 13:51:12</td>\n      <td>NaN</td>\n      <td>1321894040</td>\n      <td>7/13/2014 13:51:07</td>\n      <td>neodev</td>\n      <td>0.8333</td>\n      <td>17610000</td>\n      <td>GBR</td>\n      <td>I2</td>\n      <td>Manchester</td>\n      <td>90.200.140.201</td>\n      <td>URETHRAL OR RECTAL GONORRHEA treats IM CEFTRIA...</td>\n      <td>41</td>\n      <td>128</td>\n      <td>NaN</td>\n      <td>69</td>\n      <td>142</td>\n      <td>treats</td>\n      <td>1.000000</td>\n      <td>907845-FS1-2</td>\n      <td>For treatment of uncomplicated cervical, URETH...</td>\n      <td>URETHRAL OR RECTAL GONORRHEA</td>\n      <td>IM CEFTRIAXONE</td>\n      <td>RO-may_treat</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>502808352</td>\n      <td>7/13/2014 16:24:57</td>\n      <td>NaN</td>\n      <td>1321961909</td>\n      <td>7/13/2014 16:24:35</td>\n      <td>instagc</td>\n      <td>0.6639</td>\n      <td>25990856</td>\n      <td>USA</td>\n      <td>NV</td>\n      <td>Las Vegas</td>\n      <td>68.108.98.78</td>\n      <td>IM CEFTRIAXONE treats URETHRAL OR RECTAL GONOR...</td>\n      <td>41</td>\n      <td>128</td>\n      <td>NaN</td>\n      <td>69</td>\n      <td>142</td>\n      <td>treats</td>\n      <td>1.000000</td>\n      <td>907845-FS1-2</td>\n      <td>For treatment of uncomplicated cervical, URETH...</td>\n      <td>URETHRAL OR RECTAL GONORRHEA</td>\n      <td>IM CEFTRIAXONE</td>\n      <td>RO-may_treat</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>502808352</td>\n      <td>7/13/2014 16:33:49</td>\n      <td>NaN</td>\n      <td>1321965723</td>\n      <td>7/13/2014 16:33:31</td>\n      <td>elite</td>\n      <td>0.3923</td>\n      <td>28276268</td>\n      <td>USA</td>\n      <td>CA</td>\n      <td>San Diego</td>\n      <td>76.88.95.100</td>\n      <td>URETHRAL OR RECTAL GONORRHEA treats IM CEFTRIA...</td>\n      <td>41</td>\n      <td>128</td>\n      <td>NaN</td>\n      <td>69</td>\n      <td>142</td>\n      <td>treats</td>\n      <td>1.000000</td>\n      <td>907845-FS1-2</td>\n      <td>For treatment of uncomplicated cervical, URETH...</td>\n      <td>URETHRAL OR RECTAL GONORRHEA</td>\n      <td>IM CEFTRIAXONE</td>\n      <td>RO-may_treat</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>502808352</td>\n      <td>7/13/2014 16:47:27</td>\n      <td>NaN</td>\n      <td>1321970904</td>\n      <td>7/13/2014 16:47:06</td>\n      <td>neodev</td>\n      <td>0.6552</td>\n      <td>27597779</td>\n      <td>CAN</td>\n      <td>AB</td>\n      <td>Calgary</td>\n      <td>68.146.86.137</td>\n      <td>IM CEFTRIAXONE treats URETHRAL OR RECTAL GONOR...</td>\n      <td>41</td>\n      <td>128</td>\n      <td>NaN</td>\n      <td>69</td>\n      <td>142</td>\n      <td>treats</td>\n      <td>1.000000</td>\n      <td>907845-FS1-2</td>\n      <td>For treatment of uncomplicated cervical, URETH...</td>\n      <td>URETHRAL OR RECTAL GONORRHEA</td>\n      <td>IM CEFTRIAXONE</td>\n      <td>RO-may_treat</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>502808352</td>\n      <td>7/13/2014 16:56:13</td>\n      <td>NaN</td>\n      <td>1321973849</td>\n      <td>7/13/2014 16:55:37</td>\n      <td>clixsense</td>\n      <td>0.6639</td>\n      <td>28037714</td>\n      <td>GBR</td>\n      <td>I4</td>\n      <td>Mitcham</td>\n      <td>94.4.232.118</td>\n      <td>IM CEFTRIAXONE treats URETHRAL OR RECTAL GONOR...</td>\n      <td>41</td>\n      <td>128</td>\n      <td>NaN</td>\n      <td>69</td>\n      <td>142</td>\n      <td>treats</td>\n      <td>1.000000</td>\n      <td>907845-FS1-2</td>\n      <td>For treatment of uncomplicated cervical, URETH...</td>\n      <td>URETHRAL OR RECTAL GONORRHEA</td>\n      <td>IM CEFTRIAXONE</td>\n      <td>RO-may_treat</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>502808352</td>\n      <td>7/13/2014 17:14:41</td>\n      <td>NaN</td>\n      <td>1321979856</td>\n      <td>7/13/2014 17:14:06</td>\n      <td>prodege</td>\n      <td>0.6151</td>\n      <td>2422962</td>\n      <td>USA</td>\n      <td>IA</td>\n      <td>Honey Creek</td>\n      <td>12.73.110.97</td>\n      <td>IM CEFTRIAXONE treats URETHRAL OR RECTAL GONOR...</td>\n      <td>41</td>\n      <td>128</td>\n      <td>NaN</td>\n      <td>69</td>\n      <td>142</td>\n      <td>treats</td>\n      <td>1.000000</td>\n      <td>907845-FS1-2</td>\n      <td>For treatment of uncomplicated cervical, URETH...</td>\n      <td>URETHRAL OR RECTAL GONORRHEA</td>\n      <td>IM CEFTRIAXONE</td>\n      <td>RO-may_treat</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>502808354</td>\n      <td>7/13/2014 13:45:15</td>\n      <td>NaN</td>\n      <td>1321891302</td>\n      <td>7/13/2014 13:44:25</td>\n      <td>clixsense</td>\n      <td>0.9167</td>\n      <td>27871219</td>\n      <td>NLD</td>\n      <td>07</td>\n      <td>Amsterdam</td>\n      <td>87.210.207.223</td>\n      <td>no_relation</td>\n      <td>175</td>\n      <td>203</td>\n      <td>NaN</td>\n      <td>187</td>\n      <td>217</td>\n      <td>diagnosed by</td>\n      <td>0.530330</td>\n      <td>906321-FS1-13</td>\n      <td>Diagnosis specific malignancies available for ...</td>\n      <td>OSTEOSARCOMA</td>\n      <td>RETINOBLASTOMA</td>\n      <td>RO-has_manifestation</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>502808354</td>\n      <td>7/13/2014 13:50:45</td>\n      <td>NaN</td>\n      <td>1321893871</td>\n      <td>7/13/2014 13:50:40</td>\n      <td>neodev</td>\n      <td>0.8333</td>\n      <td>17610000</td>\n      <td>GBR</td>\n      <td>I2</td>\n      <td>Manchester</td>\n      <td>90.200.140.201</td>\n      <td>OSTEOSARCOMA diagnosed by RETINOBLASTOMA</td>\n      <td>175</td>\n      <td>203</td>\n      <td>NaN</td>\n      <td>187</td>\n      <td>217</td>\n      <td>diagnosed by</td>\n      <td>0.530330</td>\n      <td>906321-FS1-13</td>\n      <td>Diagnosis specific malignancies available for ...</td>\n      <td>OSTEOSARCOMA</td>\n      <td>RETINOBLASTOMA</td>\n      <td>RO-has_manifestation</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>502808354</td>\n      <td>7/13/2014 14:07:58</td>\n      <td>NaN</td>\n      <td>1321902037</td>\n      <td>7/13/2014 14:07:28</td>\n      <td>prodege</td>\n      <td>0.9444</td>\n      <td>23977248</td>\n      <td>GBR</td>\n      <td>B5</td>\n      <td>Wembley</td>\n      <td>82.28.55.95</td>\n      <td>no_relation</td>\n      <td>175</td>\n      <td>203</td>\n      <td>NaN</td>\n      <td>187</td>\n      <td>217</td>\n      <td>diagnosed by</td>\n      <td>0.530330</td>\n      <td>906321-FS1-13</td>\n      <td>Diagnosis specific malignancies available for ...</td>\n      <td>OSTEOSARCOMA</td>\n      <td>RETINOBLASTOMA</td>\n      <td>RO-has_manifestation</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>502808354</td>\n      <td>7/13/2014 14:38:06</td>\n      <td>NaN</td>\n      <td>1321916349</td>\n      <td>7/13/2014 14:37:50</td>\n      <td>instagc</td>\n      <td>0.7431</td>\n      <td>15445601</td>\n      <td>USA</td>\n      <td>FL</td>\n      <td>Jacksonville</td>\n      <td>24.129.68.254</td>\n      <td>no_relation</td>\n      <td>175</td>\n      <td>203</td>\n      <td>NaN</td>\n      <td>187</td>\n      <td>217</td>\n      <td>diagnosed by</td>\n      <td>0.530330</td>\n      <td>906321-FS1-13</td>\n      <td>Diagnosis specific malignancies available for ...</td>\n      <td>OSTEOSARCOMA</td>\n      <td>RETINOBLASTOMA</td>\n      <td>RO-has_manifestation</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>502808354</td>\n      <td>7/13/2014 16:14:39</td>\n      <td>NaN</td>\n      <td>1321958228</td>\n      <td>7/13/2014 16:13:26</td>\n      <td>instagc</td>\n      <td>0.7496</td>\n      <td>22391553</td>\n      <td>CAN</td>\n      <td>NB</td>\n      <td>Bathurst</td>\n      <td>156.34.43.239</td>\n      <td>no_relation</td>\n      <td>175</td>\n      <td>203</td>\n      <td>NaN</td>\n      <td>187</td>\n      <td>217</td>\n      <td>diagnosed by</td>\n      <td>0.530330</td>\n      <td>906321-FS1-13</td>\n      <td>Diagnosis specific malignancies available for ...</td>\n      <td>OSTEOSARCOMA</td>\n      <td>RETINOBLASTOMA</td>\n      <td>RO-has_manifestation</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>502808354</td>\n      <td>7/13/2014 16:41:45</td>\n      <td>NaN</td>\n      <td>1321968893</td>\n      <td>7/13/2014 16:41:08</td>\n      <td>instagc</td>\n      <td>0.7262</td>\n      <td>24252915</td>\n      <td>GBR</td>\n      <td>B7</td>\n      <td>Bristol</td>\n      <td>77.98.139.82</td>\n      <td>no_relation</td>\n      <td>175</td>\n      <td>203</td>\n      <td>NaN</td>\n      <td>187</td>\n      <td>217</td>\n      <td>diagnosed by</td>\n      <td>0.530330</td>\n      <td>906321-FS1-13</td>\n      <td>Diagnosis specific malignancies available for ...</td>\n      <td>OSTEOSARCOMA</td>\n      <td>RETINOBLASTOMA</td>\n      <td>RO-has_manifestation</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>502808354</td>\n      <td>7/13/2014 16:46:18</td>\n      <td>NaN</td>\n      <td>1321970376</td>\n      <td>7/13/2014 16:45:49</td>\n      <td>neodev</td>\n      <td>0.6552</td>\n      <td>27597779</td>\n      <td>CAN</td>\n      <td>AB</td>\n      <td>Calgary</td>\n      <td>68.146.86.137</td>\n      <td>no_relation</td>\n      <td>175</td>\n      <td>203</td>\n      <td>NaN</td>\n      <td>187</td>\n      <td>217</td>\n      <td>diagnosed by</td>\n      <td>0.530330</td>\n      <td>906321-FS1-13</td>\n      <td>Diagnosis specific malignancies available for ...</td>\n      <td>OSTEOSARCOMA</td>\n      <td>RETINOBLASTOMA</td>\n      <td>RO-has_manifestation</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>502808355</td>\n      <td>7/13/2014 13:51:12</td>\n      <td>NaN</td>\n      <td>1321894041</td>\n      <td>7/13/2014 13:51:07</td>\n      <td>neodev</td>\n      <td>0.8333</td>\n      <td>17610000</td>\n      <td>GBR</td>\n      <td>I2</td>\n      <td>Manchester</td>\n      <td>90.200.140.201</td>\n      <td>ALLERGY contraindicates NON ALLERGY</td>\n      <td>115</td>\n      <td>151</td>\n      <td>NaN</td>\n      <td>122</td>\n      <td>162</td>\n      <td>contraindicates</td>\n      <td>0.471405</td>\n      <td>900413-FS1-10</td>\n      <td>Acute steady state moderate exercise significa...</td>\n      <td>ALLERGY</td>\n      <td>NON ALLERGY</td>\n      <td>RO-cause_of</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>502808355</td>\n      <td>7/13/2014 14:45:21</td>\n      <td>NaN</td>\n      <td>1321920117</td>\n      <td>7/13/2014 14:45:05</td>\n      <td>neodev</td>\n      <td>0.7569</td>\n      <td>14861092</td>\n      <td>GBR</td>\n      <td>I2</td>\n      <td>Manchester</td>\n      <td>90.194.137.76</td>\n      <td>no_relation</td>\n      <td>115</td>\n      <td>151</td>\n      <td>NaN</td>\n      <td>122</td>\n      <td>162</td>\n      <td>contraindicates</td>\n      <td>0.471405</td>\n      <td>900413-FS1-10</td>\n      <td>Acute steady state moderate exercise significa...</td>\n      <td>ALLERGY</td>\n      <td>NON ALLERGY</td>\n      <td>RO-cause_of</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>502808355</td>\n      <td>7/13/2014 15:02:14</td>\n      <td>NaN</td>\n      <td>1321929335</td>\n      <td>7/13/2014 15:01:45</td>\n      <td>clixsense</td>\n      <td>0.6917</td>\n      <td>15189335</td>\n      <td>GBR</td>\n      <td>K3</td>\n      <td>Peterborough</td>\n      <td>81.156.166.189</td>\n      <td>no_relation</td>\n      <td>115</td>\n      <td>151</td>\n      <td>NaN</td>\n      <td>122</td>\n      <td>162</td>\n      <td>contraindicates</td>\n      <td>0.471405</td>\n      <td>900413-FS1-10</td>\n      <td>Acute steady state moderate exercise significa...</td>\n      <td>ALLERGY</td>\n      <td>NON ALLERGY</td>\n      <td>RO-cause_of</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>502808355</td>\n      <td>7/13/2014 15:33:06</td>\n      <td>NaN</td>\n      <td>1321942103</td>\n      <td>7/13/2014 15:32:56</td>\n      <td>prodege</td>\n      <td>0.6210</td>\n      <td>2143114</td>\n      <td>CAN</td>\n      <td>BC</td>\n      <td>Vancouver</td>\n      <td>24.84.160.12</td>\n      <td>ALLERGY contraindicates NON ALLERGY</td>\n      <td>115</td>\n      <td>151</td>\n      <td>NaN</td>\n      <td>122</td>\n      <td>162</td>\n      <td>contraindicates</td>\n      <td>0.471405</td>\n      <td>900413-FS1-10</td>\n      <td>Acute steady state moderate exercise significa...</td>\n      <td>ALLERGY</td>\n      <td>NON ALLERGY</td>\n      <td>RO-cause_of</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>502808355</td>\n      <td>7/13/2014 15:58:57</td>\n      <td>NaN</td>\n      <td>1321952088</td>\n      <td>7/13/2014 15:58:31</td>\n      <td>prodege</td>\n      <td>0.6690</td>\n      <td>27096445</td>\n      <td>GBR</td>\n      <td>H9</td>\n      <td>London</td>\n      <td>86.186.168.254</td>\n      <td>no_relation</td>\n      <td>115</td>\n      <td>151</td>\n      <td>NaN</td>\n      <td>122</td>\n      <td>162</td>\n      <td>contraindicates</td>\n      <td>0.471405</td>\n      <td>900413-FS1-10</td>\n      <td>Acute steady state moderate exercise significa...</td>\n      <td>ALLERGY</td>\n      <td>NON ALLERGY</td>\n      <td>RO-cause_of</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>502808355</td>\n      <td>7/13/2014 16:01:02</td>\n      <td>NaN</td>\n      <td>1321952900</td>\n      <td>7/13/2014 16:00:21</td>\n      <td>prodege</td>\n      <td>0.5960</td>\n      <td>27934334</td>\n      <td>GBR</td>\n      <td>E4</td>\n      <td>Loughton</td>\n      <td>86.162.38.12</td>\n      <td>no_relation</td>\n      <td>115</td>\n      <td>151</td>\n      <td>NaN</td>\n      <td>122</td>\n      <td>162</td>\n      <td>contraindicates</td>\n      <td>0.471405</td>\n      <td>900413-FS1-10</td>\n      <td>Acute steady state moderate exercise significa...</td>\n      <td>ALLERGY</td>\n      <td>NON ALLERGY</td>\n      <td>RO-cause_of</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['relation'].unique()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"array(['treats', 'diagnosed by', 'contraindicates', 'causes', 'location',\n       'is location of', 'location of', 'is diagnosed by',\n       'diagnose_by_test_or_drug'], dtype=object)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"<p>Transformamos as sentenças e tipos de relacionamento em matrizes numpy. Também binarizamos os rótulos dos relacionamentos, para utilizarmos no nosso classificador logo mais.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nx_train = df_train['sentence'].as_matrix()\ny_train = df_train['relation'].as_matrix()\n\nfrom sklearn.preprocessing import label_binarize\n\ny_train = label_binarize(y_train, classes=df_train['relation'].unique())\n\nprint(x_train[:10])\nprint(y_train[:10])","execution_count":3,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n  after removing the cwd from sys.path.\n","name":"stderr"},{"output_type":"stream","text":"['For treatment of uncomplicated cervical, URETHRAL OR RECTAL GONORRHEA CDC and others recommend IM ceftriaxone or oral cefixime; IM CEFTRIAXONE is drug of choice for pharyngeal infections.'\n 'For treatment of uncomplicated cervical, URETHRAL OR RECTAL GONORRHEA CDC and others recommend IM ceftriaxone or oral cefixime; IM CEFTRIAXONE is drug of choice for pharyngeal infections.'\n 'For treatment of uncomplicated cervical, URETHRAL OR RECTAL GONORRHEA CDC and others recommend IM ceftriaxone or oral cefixime; IM CEFTRIAXONE is drug of choice for pharyngeal infections.'\n 'For treatment of uncomplicated cervical, URETHRAL OR RECTAL GONORRHEA CDC and others recommend IM ceftriaxone or oral cefixime; IM CEFTRIAXONE is drug of choice for pharyngeal infections.'\n 'For treatment of uncomplicated cervical, URETHRAL OR RECTAL GONORRHEA CDC and others recommend IM ceftriaxone or oral cefixime; IM CEFTRIAXONE is drug of choice for pharyngeal infections.'\n 'For treatment of uncomplicated cervical, URETHRAL OR RECTAL GONORRHEA CDC and others recommend IM ceftriaxone or oral cefixime; IM CEFTRIAXONE is drug of choice for pharyngeal infections.'\n 'For treatment of uncomplicated cervical, URETHRAL OR RECTAL GONORRHEA CDC and others recommend IM ceftriaxone or oral cefixime; IM CEFTRIAXONE is drug of choice for pharyngeal infections.'\n \"Diagnosis specific malignancies available for evaluation included ALL, acute myeloid leukaemia (AML), Hodgkin's disease, NHL, rhabdomyosarcoma, neuroblastoma, retinoblastoma, OSTEOSARCOMA Wilms' tumour, RETINOBLASTOMA Ewings' sarcoma, central nervous system (CNS) tumours and hepatoblastoma.\"\n \"Diagnosis specific malignancies available for evaluation included ALL, acute myeloid leukaemia (AML), Hodgkin's disease, NHL, rhabdomyosarcoma, neuroblastoma, retinoblastoma, OSTEOSARCOMA Wilms' tumour, RETINOBLASTOMA Ewings' sarcoma, central nervous system (CNS) tumours and hepatoblastoma.\"\n \"Diagnosis specific malignancies available for evaluation included ALL, acute myeloid leukaemia (AML), Hodgkin's disease, NHL, rhabdomyosarcoma, neuroblastoma, retinoblastoma, OSTEOSARCOMA Wilms' tumour, RETINOBLASTOMA Ewings' sarcoma, central nervous system (CNS) tumours and hepatoblastoma.\"]\n[[1 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0]]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<p>Como não temos os tipos das entidades, mas sabemos que se trata de nomes de medicamentos e doenças na maioria dos casos, não utilizaremos o tipo das entidades como atributos, mas utilizaremos os POS tags de todas as palavras entre as entidades. Vamos criar outras matrizes com esses atributos. </p>\n\n<p>Para os POS Tags, vamos fazer algo parecido ao chunking sugerido em https://courses.cs.washington.edu/courses/cse517/13wi/slides/cse517wi13-RelationExtraction.pdf, mas ao invés de usar chunking, vamos criar 3-grams desses POS tags para simplificar.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_sub_list = []\n\nfor i, row in df_train.iterrows():\n    pos_t1 = row['sentence'].find(row['term1'])\n    len_t1 = len(row['term1'])\n    \n    pos_t2 = row['sentence'].find(row['term2'])    \n    \n    x_train_sub_list.append(row['sentence'][pos_t1+len_t1:pos_t2])\n    \n\nx_train_sub = np.array(x_train_sub_list)\n\nprint(x_train_sub[:10])","execution_count":4,"outputs":[{"output_type":"stream","text":"[' CDC and others recommend IM ceftriaxone or oral cefixime; '\n ' CDC and others recommend IM ceftriaxone or oral cefixime; '\n ' CDC and others recommend IM ceftriaxone or oral cefixime; '\n ' CDC and others recommend IM ceftriaxone or oral cefixime; '\n ' CDC and others recommend IM ceftriaxone or oral cefixime; '\n ' CDC and others recommend IM ceftriaxone or oral cefixime; '\n ' CDC and others recommend IM ceftriaxone or oral cefixime; '\n \" Wilms' tumour, \" \" Wilms' tumour, \" \" Wilms' tumour, \"]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<p>Agora vamos definir duas funções de tokenização: uma para tokenizar bag-of-words e outra para tokenizar os POS tags</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nimport string\nfrom nltk.corpus import wordnet\n\ndef my_tokenizer_pos(doc):\n    words = word_tokenize(doc)\n    \n    pos_tags = pos_tag(words)\n    \n    return [pos[1] for pos in pos_tags]\n\n# testando nossa função:\n\nfor x in x_train_sub[:10]:\n    print(my_tokenizer_pos(x))","execution_count":5,"outputs":[{"output_type":"stream","text":"['NNP', 'CC', 'NNS', 'VBP', 'NNP', 'NN', 'CC', 'JJ', 'NN', ':']\n['NNP', 'CC', 'NNS', 'VBP', 'NNP', 'NN', 'CC', 'JJ', 'NN', ':']\n['NNP', 'CC', 'NNS', 'VBP', 'NNP', 'NN', 'CC', 'JJ', 'NN', ':']\n['NNP', 'CC', 'NNS', 'VBP', 'NNP', 'NN', 'CC', 'JJ', 'NN', ':']\n['NNP', 'CC', 'NNS', 'VBP', 'NNP', 'NN', 'CC', 'JJ', 'NN', ':']\n['NNP', 'CC', 'NNS', 'VBP', 'NNP', 'NN', 'CC', 'JJ', 'NN', ':']\n['NNP', 'CC', 'NNS', 'VBP', 'NNP', 'NN', 'CC', 'JJ', 'NN', ':']\n['NNP', 'POS', 'NN', ',']\n['NNP', 'POS', 'NN', ',']\n['NNP', 'POS', 'NN', ',']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords_list = stopwords.words('english')\n\nlemmatizer = WordNetLemmatizer()\n\ndef my_tokenizer_bow(doc):\n    words = word_tokenize(doc)\n    \n    pos_tags = pos_tag(words)\n    \n    non_stopwords = [w for w in pos_tags if not w[0].lower() in stopwords_list]\n    \n    non_punctuation = [w for w in non_stopwords if not w[0] in string.punctuation]\n    \n    lemmas = []\n    for w in non_punctuation:\n        if w[1].startswith('J'):\n            pos = wordnet.ADJ\n        elif w[1].startswith('V'):\n            pos = wordnet.VERB\n        elif w[1].startswith('N'):\n            pos = wordnet.NOUN\n        elif w[1].startswith('R'):\n            pos = wordnet.ADV\n        else:\n            pos = wordnet.NOUN\n        \n        lemmas.append(lemmatizer.lemmatize(w[0], pos))\n\n    return lemmas","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Vamos reaproveitar a classe para seleção de atributos usando SVD.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\n\nclass SVDDimSelect(object):\n    def fit(self, X, y=None):        \n        try:\n            self.svd_transformer = TruncatedSVD(n_components=round(X.shape[1]/2))\n            self.svd_transformer.fit(X)\n        \n            cummulative_variance = 0.0\n            k = 0\n            for var in sorted(self.svd_transformer.explained_variance_ratio_)[::-1]:\n                cummulative_variance += var\n                if cummulative_variance >= 0.5:\n                    break\n                else:\n                    k += 1\n                \n            self.svd_transformer = TruncatedSVD(n_components=k)\n        except Exception as ex:\n            print(ex)\n            \n        return self.svd_transformer.fit(X)\n    \n    def transform(self, X, Y=None):\n        return self.svd_transformer.transform(X)\n        \n    def get_params(self, deep=True):\n        return {}","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Agora vamos criar nosso Pipeline. Em resumo, vamos usar o TFIDF Vectorizer e o nosso POS Tagger em paralelo, e depois juntar os atributos para redimensionar usando o SVD.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nimport scipy\n\nclf = OneVsRestClassifier(LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial'))\n\n\nmy_pipeline = Pipeline([\n                        ('union', FeatureUnion([('bow', TfidfVectorizer(tokenizer=my_tokenizer_bow)),\\\n                                                ('pos', Pipeline([('pos-vect', CountVectorizer(tokenizer=my_tokenizer_pos)), \\\n                                                         ('pos-tfidf', TfidfTransformer())]))\n                                               ])),\\\n                       ('svd', SVDDimSelect()), \\\n                       ('clf', clf)])\n\npar = {'clf__estimator__C' : np.logspace(-4, 4, 20)}\n\nhyperpar_selector = RandomizedSearchCV(my_pipeline, par, cv=3, scoring='f1_weighted', n_jobs=1, n_iter=20)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Agora vamos treinar os algoritmos</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train_sub.shape)\nprint(y_train.shape)\n\nhyperpar_selector.fit(X=x_train_sub, y=y_train)","execution_count":9,"outputs":[{"output_type":"stream","text":"(13340,)\n(13340, 9)\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 4 is present in all training examples.\n  str(classes[c]))\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 6 is present in all training examples.\n  str(classes[c]))\n/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 7 is present in all training examples.\n  str(classes[c]))\n/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 8 is present in all training examples.\n  str(classes[c]))\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 4 is present in all training examples.\n  str(classes[c]))\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 6 is present in all training examples.\n  str(classes[c]))\n/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 7 is present in all training examples.\n  str(classes[c]))\n/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 8 is present in all training examples.\n  str(classes[c]))\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 4 is present in all training examples.\n  str(classes[c]))\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 6 is present in all training examples.\n  str(classes[c]))\n/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 7 is present in all training examples.\n  str(classes[c]))\n/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 8 is present in all training examples.\n  str(classes[c]))\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n","name":"stderr"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 4 is present in all training examples.\n  str(classes[c]))\n","name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-a10b784ec269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhyperpar_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             random_state=self.random_state))\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \"\"\"\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \"\"\"\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    820\u001b[0m         Xs = Parallel(n_jobs=self.n_jobs)(\n\u001b[1;32m    821\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m             for name, trans, weight in self._iter())\n\u001b[0m\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;31m# All transformers are None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m     \u001b[0;31m# if we have a weight for this transformer, multiply output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1639\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'The tfidf vector is not fitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    327\u001b[0m                                                tokenize)\n\u001b[1;32m    328\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 329\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-c71a61b21f95>\u001b[0m in \u001b[0;36mmy_tokenizer_bow\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mlemmas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlemmas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_morphy\u001b[0;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[1;32m   1801\u001b[0m         \u001b[0;31m# 3. If there are no matches, keep applying rules until we find a match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1803\u001b[0;31m             \u001b[0mforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1804\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_forms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mapply_rules\u001b[0;34m(forms)\u001b[0m\n\u001b[1;32m   1770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1772\u001b[0;31m             return [form[:-len(old)] + new\n\u001b[0m\u001b[1;32m   1773\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubstitutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = df_test['sentence'].as_matrix()\ny_test = df_test['relation'].as_matrix()\n\ny_test = label_binarize(y_test, classes=df_train['relation'].unique())\n\nx_test_sub_list = []\n\nfor i, row in df_test.iterrows():\n    pos_t1 = row['sentence'].find(row['term1'])\n    pos_t2 = row['sentence'].find(row['term2'])    \n\n    if pos_t1 < pos_t2:\n        len_t1 = len(row['term1'])    \n        x_test_sub_list.append(row['sentence'][pos_t1+len_t1:pos_t2])\n    else:\n        len_t2 = len(row['term2'])    \n        x_test_sub_list.append(row['sentence'][pos_t2+len_t2:pos_t1])\n    \n\nx_test_sub = np.array(x_test_sub_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predicted = hyperpar_selector.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_predicted, target_names=df_train['relation'].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>\n</p>"},{"metadata":{},"cell_type":"markdown","source":"<p><b>Exercício 7:</b> Treine um modelo de extração de relacionamentos em Português, utilizando o corpus extraído do DBPedia e com relacionamentos entre pares de entidades anotadas.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = False\nlista = []\nwith open('../input/dbpedia-with-entity-relations-in-portuguese/DBpediaRelations-PT-0.2.txt') as file:\n    for line in file:\n        if(line.strip() == '*********'):\n            break\n        if(line.strip() == '****************************'):\n            if (not start):\n                dic = {}\n            else:\n                #print(dic)\n                lista.append(dic)\n            start = ~start\n        else:\n            if (start):\n                if (line.strip() != ''):\n                    #print(line)\n                    aux = line.split(':')\n                    if(len(aux) < 2):\n                        print(aux)\n                    dic[aux[0].strip()] = aux[1].strip()","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nrandom.seed(42)\nporcentagem = 0.7\nmask = np.ones(int(len(lista)*porcentagem))\nmask = np.concatenate((mask, np.zeros(len(lista) - len(mask)))) == 1\nrandom.shuffle(mask)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lista = pd.DataFrame(lista)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treino = lista[mask]\nteste = lista[~mask]","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"teste[:10]","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"            ENTITY1       ENTITY2    ...        TYPE1     TYPE2\n2    América Latina        Brasil    ...     LOCATION  LOCATION\n5   Albert Einstein           Ulm    ...       PERSON  LOCATION\n14      Afeganistão      Kandahar    ...     LOCATION  LOCATION\n15      Afeganistão  Hamid Karzai    ...     LOCATION    PERSON\n17           Angola        Luanda    ...     LOCATION  LOCATION\n18           Angola        Luanda    ...     LOCATION  LOCATION\n19           Angola        Luanda    ...     LOCATION  LOCATION\n23         Amazonas        Manaus    ...     LOCATION  LOCATION\n27         Amazonas         Maués    ...     LOCATION  LOCATION\n29         Amazonas        Manaus    ...     LOCATION  LOCATION\n\n[10 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ENTITY1</th>\n      <th>ENTITY2</th>\n      <th>MANUALLY CHECKED</th>\n      <th>REL TYPE</th>\n      <th>SENTENCE</th>\n      <th>TYPE1</th>\n      <th>TYPE2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>América Latina</td>\n      <td>Brasil</td>\n      <td>TRUE</td>\n      <td>locatedInArea</td>\n      <td>A América Latina destaca-se ainda por sua prod...</td>\n      <td>LOCATION</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Albert Einstein</td>\n      <td>Ulm</td>\n      <td>TRUE</td>\n      <td>origin</td>\n      <td>É em Ulm que nasce Albert Einstein, em 14 de m...</td>\n      <td>PERSON</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Afeganistão</td>\n      <td>Kandahar</td>\n      <td>TRUE</td>\n      <td>other</td>\n      <td>A capital do Afeganistão foi transferida em 17...</td>\n      <td>LOCATION</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Afeganistão</td>\n      <td>Hamid Karzai</td>\n      <td>TRUE</td>\n      <td>keyPerson</td>\n      <td>Em dezembro de 2001 o Conselho de Segurança da...</td>\n      <td>LOCATION</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Angola</td>\n      <td>Luanda</td>\n      <td>TRUE</td>\n      <td>other</td>\n      <td>O nome Angola é uma derivação portuguesa do te...</td>\n      <td>LOCATION</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Angola</td>\n      <td>Luanda</td>\n      <td>TRUE</td>\n      <td>other</td>\n      <td>No dia 11 de novembro de 1975 foi proclamada a...</td>\n      <td>LOCATION</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Angola</td>\n      <td>Luanda</td>\n      <td>TRUE</td>\n      <td>other</td>\n      <td>Em Angola, e mais especialmente em Luanda, a e...</td>\n      <td>LOCATION</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Amazonas</td>\n      <td>Manaus</td>\n      <td>TRUE</td>\n      <td>other</td>\n      <td>Ganhou a condição de Província do Amazonas pel...</td>\n      <td>LOCATION</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Amazonas</td>\n      <td>Maués</td>\n      <td>TRUE</td>\n      <td>other</td>\n      <td>Chegaram ao Amazonas os primeiros imigrantes, ...</td>\n      <td>LOCATION</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Amazonas</td>\n      <td>Manaus</td>\n      <td>TRUE</td>\n      <td>other</td>\n      <td>O Amazonas possui várias instituições educacio...</td>\n      <td>LOCATION</td>\n      <td>LOCATION</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"treino[:10]","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"                   ENTITY1      ENTITY2    ...        TYPE1     TYPE2\n0           América Latina    Argentina    ...     LOCATION  LOCATION\n1           América Latina       Brasil    ...     LOCATION  LOCATION\n3          Albert Einstein          Ulm    ...       PERSON  LOCATION\n4          Albert Einstein  Württemberg    ...       PERSON  LOCATION\n6                  Adriano      Trajano    ...       PERSON    PERSON\n7                  Adriano       Itália    ...       PERSON  LOCATION\n8                  Adriano      Trajano    ...       PERSON    PERSON\n9                  Adriano      Trajano    ...       PERSON    PERSON\n10  Dom Afonso de Portugal       Lisboa    ...       PERSON  LOCATION\n11  Dom Afonso de Portugal     Santarém    ...       PERSON  LOCATION\n\n[10 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ENTITY1</th>\n      <th>ENTITY2</th>\n      <th>MANUALLY CHECKED</th>\n      <th>REL TYPE</th>\n      <th>SENTENCE</th>\n      <th>TYPE1</th>\n      <th>TYPE2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>América Latina</td>\n      <td>Argentina</td>\n      <td>TRUE</td>\n      <td>locatedInArea</td>\n      <td>A América Latina localiza-se totalmente no hem...</td>\n      <td>LOCATION</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>América Latina</td>\n      <td>Brasil</td>\n      <td>TRUE</td>\n      <td>locatedInArea</td>\n      <td>A América Latina não apresenta, ao contrário d...</td>\n      <td>LOCATION</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albert Einstein</td>\n      <td>Ulm</td>\n      <td>TRUE</td>\n      <td>origin</td>\n      <td>Albert Einstein nasceu na região alemã de Würt...</td>\n      <td>PERSON</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albert Einstein</td>\n      <td>Württemberg</td>\n      <td>TRUE</td>\n      <td>origin</td>\n      <td>Albert Einstein nasceu na região alemã de Würt...</td>\n      <td>PERSON</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Adriano</td>\n      <td>Trajano</td>\n      <td>TRUE</td>\n      <td>successor</td>\n      <td>Nascido em Itálica na atual Espanha, ou em Rom...</td>\n      <td>PERSON</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Adriano</td>\n      <td>Itália</td>\n      <td>TRUE</td>\n      <td>origin</td>\n      <td>Nascido em Itálica na atual Espanha, ou em Rom...</td>\n      <td>PERSON</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Adriano</td>\n      <td>Trajano</td>\n      <td>TRUE</td>\n      <td>successor</td>\n      <td>Talvez por entender que o império esgotara sua...</td>\n      <td>PERSON</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Adriano</td>\n      <td>Trajano</td>\n      <td>TRUE</td>\n      <td>successor</td>\n      <td>Adriano também retificou os limites de uma out...</td>\n      <td>PERSON</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Dom Afonso de Portugal</td>\n      <td>Lisboa</td>\n      <td>TRUE</td>\n      <td>origin</td>\n      <td>Dom Afonso de Portugal (Lisboa, 18 de Maio de ...</td>\n      <td>PERSON</td>\n      <td>LOCATION</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Dom Afonso de Portugal</td>\n      <td>Santarém</td>\n      <td>TRUE</td>\n      <td>deathOrBurialPlace</td>\n      <td>Dom Afonso de Portugal (Lisboa, 18 de Maio de ...</td>\n      <td>PERSON</td>\n      <td>LOCATION</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"treino['REL TYPE'].unique()","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"array(['locatedInArea', 'origin', 'successor', 'deathOrBurialPlace',\n       'other', 'keyPerson', 'partOf', 'influencedBy', 'partner',\n       'parent'], dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nx_train = treino['SENTENCE'].as_matrix()\ny_train = treino['REL TYPE'].as_matrix()\n\nfrom sklearn.preprocessing import label_binarize\n\ny_train = label_binarize(y_train, classes=treino['REL TYPE'].unique())\n\nprint(x_train[:10])\nprint(y_train[:10])","execution_count":17,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n  after removing the cwd from sys.path.\n","name":"stderr"},{"output_type":"stream","text":"['A América Latina localiza-se totalmente no hemisfério ocidental, sendo atravessada pelo Trópico de Câncer, que corta a parte central do México; pelo Equador, que passa pelo Brasil, Colômbia, Equador e toca o norte do Peru; e pelo Trópico de Capricórnio, que atravessa o Brasil, o Paraguai, a Argentina e o Chile.'\n 'A América Latina não apresenta, ao contrário da América do Norte, grandes extensões lacustres, mas ainda assim possui inúmeras lagoas costeiras, sobretudo na vertente atlântica, como a lagoa dos Patos, no Brasil; lagoas de inundação nas planícies Amazônica e do Orinoco; e lagos de altitude, como o Titicaca, entre o Peru e a Bolívia.'\n 'Albert Einstein nasceu na região alemã de Württemberg, na cidade de Ulm, numa família judaica.'\n 'Albert Einstein nasceu na região alemã de Württemberg, na cidade de Ulm, numa família judaica.'\n 'Nascido em Itálica na atual Espanha, ou em Roma, na Itália, Adriano era descendente de colonos romanos domiciliados no Sul da Hispânia e primo de Trajano, tendo sido nomeado por este para uma série de dignidades públicas que o fizeram aparecer como herdeiro presuntivo deste imperador.'\n 'Nascido em Itálica na atual Espanha, ou em Roma, na Itália, Adriano era descendente de colonos romanos domiciliados no Sul da Hispânia e primo de Trajano, tendo sido nomeado por este para uma série de dignidades públicas que o fizeram aparecer como herdeiro presuntivo deste imperador.'\n 'Talvez por entender que o império esgotara sua capacidade de expansão, Adriano abandonou a política de conquistas de Trajano, adotando outra nitidamente defensiva, optando pela via diplomática para resolver questões relativas ao relacionamento com povos vizinhos.'\n 'Adriano também retificou os limites de uma outra conquista de Trajano, esta já antiga, a Dácia (atual Roménia), cedendo aos sármatas a planície do Baixo Danúbio e concentrando a ocupação romana na região da Transilvânia, protegida pela barreira natural dos Cárpatos.'\n 'Dom Afonso de Portugal (Lisboa, 18 de Maio de 1475 – Santarém, 13 de Julho de 1491) era filho único.'\n 'Dom Afonso de Portugal (Lisboa, 18 de Maio de 1475 – Santarém, 13 de Julho de 1491) era filho único.']\n[[1 0 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0 0]\n [0 0 1 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0 0]\n [0 0 1 0 0 0 0 0 0 0]\n [0 0 1 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0 0]\n [0 0 0 1 0 0 0 0 0 0]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_sub_list = []\n\nfor i, row in treino.iterrows():\n    pos_t1 = row['SENTENCE'].find(row['ENTITY1'])\n    len_t1 = len(row['ENTITY1'])\n    \n    pos_t2 = row['SENTENCE'].find(row['ENTITY2'])    \n    \n    x_train_sub_list.append(row['SENTENCE'][pos_t1+len_t1:pos_t2])\n    \n\nx_train_sub = np.array(x_train_sub_list)\n\nprint(x_train_sub[:10])","execution_count":18,"outputs":[{"output_type":"stream","text":"[' localiza-se totalmente no hemisfério ocidental, sendo atravessada pelo Trópico de Câncer, que corta a parte central do México; pelo Equador, que passa pelo Brasil, Colômbia, Equador e toca o norte do Peru; e pelo Trópico de Capricórnio, que atravessa o Brasil, o Paraguai, a '\n ' não apresenta, ao contrário da América do Norte, grandes extensões lacustres, mas ainda assim possui inúmeras lagoas costeiras, sobretudo na vertente atlântica, como a lagoa dos Patos, no '\n ' nasceu na região alemã de Württemberg, na cidade de '\n ' nasceu na região alemã de '\n ' era descendente de colonos romanos domiciliados no Sul da Hispânia e primo de '\n '' ' abandonou a política de conquistas de '\n ' também retificou os limites de uma outra conquista de ' ' ('\n ' (Lisboa, 18 de Maio de 1475 – ']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nimport string\nfrom nltk.corpus import wordnet\n\ndef my_tokenizer_pos(doc):\n    words = word_tokenize(doc)\n    \n    pos_tags = pos_tag(words)\n    \n    return [pos[1] for pos in pos_tags]\n\n# testando nossa função:\n\nfor x in x_train_sub[:10]:\n    print(my_tokenizer_pos(x))","execution_count":19,"outputs":[{"output_type":"stream","text":"['JJ', 'NN', 'DT', 'NN', 'NN', ',', 'VBP', 'JJ', 'NN', 'NNP', 'FW', 'NNP', ',', 'NN', 'VBD', 'DT', 'JJ', 'JJ', 'VBP', 'NNP', ':', 'NN', 'NNP', ',', 'NN', 'NN', 'NN', 'NNP', ',', 'NNP', ',', 'NNP', 'VBZ', 'JJ', 'NN', 'NNS', 'VBP', 'NNP', ':', 'CC', 'VB', 'NNP', 'FW', 'NNP', ',', 'NN', 'NN', 'NN', 'NNP', ',', 'NN', 'NNP', ',', 'DT']\n['JJ', 'NN', ',', 'VBP', 'NN', 'NN', 'NNP', 'VBP', 'NNP', ',', 'VBZ', 'JJ', 'NNS', ',', 'FW', 'FW', 'FW', 'FW', 'FW', 'FW', 'NNS', ',', 'NN', 'TO', 'NN', 'NN', ',', 'VB', 'DT', 'JJ', 'NN', 'NNP', ',', 'DT']\n['RB', 'JJ', 'NN', 'NN', 'IN', 'NNP', ',', 'RB', 'NN', 'IN']\n['RB', 'JJ', 'NN', 'NN', 'IN']\n['NN', 'NN', 'IN', 'FW', 'NNS', 'VBP', 'DT', 'NNP', 'VBZ', 'NNP', 'NN', 'NN', 'IN']\n[]\n['VB', 'DT', 'NN', 'IN', 'FW', 'FW']\n['NN', 'NN', 'JJ', 'VBZ', 'FW', 'FW', 'JJ', 'NN', 'IN']\n['(']\n['(', 'NNP', ',', 'CD', 'FW', 'NNP', 'IN', 'CD', 'NN']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python -m spacy download pt_core_news_sm","execution_count":21,"outputs":[{"output_type":"stream","text":"Collecting pt_core_news_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.1.0/pt_core_news_sm-2.1.0.tar.gz#egg=pt_core_news_sm==2.1.0\n\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.1.0/pt_core_news_sm-2.1.0.tar.gz (12.8MB)\n\u001b[K    100% |████████████████████████████████| 12.9MB 94.1MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: pt-core-news-sm\n  Running setup.py install for pt-core-news-sm ... \u001b[?25ldone\n\u001b[?25hSuccessfully installed pt-core-news-sm-2.1.0\n\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the model via spacy.load('pt_core_news_sm')\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pt_core_news_sm\n\nnlp = pt_core_news_sm.load()","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.stem import RSLPStemmer\n\nstopwords_list = stopwords.words('portuguese')\n\nstemmer = nltk.stem.RSLPStemmer()","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_tokenizer_bow(doc):\n    words = word_tokenize(doc)\n    \n    non_stopwords = [w for w in words if not w[0].lower() in stopwords_list]\n    \n    non_punctuation = [w for w in non_stopwords if not w[0] in string.punctuation]\n    \n    lemmas = []\n    for w in non_punctuation:\n        \n        lemmas.append(stemmer.stem(w))\n\n    return lemmas","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\n\nclass SVDDimSelect(object):\n    def fit(self, X, y=None):        \n        try:\n            self.svd_transformer = TruncatedSVD(n_components=round(X.shape[1]/2))\n            self.svd_transformer.fit(X)\n        \n            cummulative_variance = 0.0\n            k = 0\n            for var in sorted(self.svd_transformer.explained_variance_ratio_)[::-1]:\n                cummulative_variance += var\n                if cummulative_variance >= 0.5:\n                    break\n                else:\n                    k += 1\n                \n            self.svd_transformer = TruncatedSVD(n_components=k)\n        except Exception as ex:\n            print(ex)\n            \n        return self.svd_transformer.fit(X)\n    \n    def transform(self, X, Y=None):\n        return self.svd_transformer.transform(X)\n        \n    def get_params(self, deep=True):\n        return {}","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nimport scipy\n\nclf = OneVsRestClassifier(LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial'))\n\n\nmy_pipeline = Pipeline([\n                        ('union', FeatureUnion([('bow', TfidfVectorizer(tokenizer=my_tokenizer_bow)),\\\n                                                ('pos', Pipeline([('pos-vect', CountVectorizer(tokenizer=my_tokenizer_pos)), \\\n                                                         ('pos-tfidf', TfidfTransformer())]))\n                                               ])),\\\n                       ('svd', SVDDimSelect()), \\\n                       ('clf', clf)])\n\npar = {'clf__estimator__C' : np.logspace(-4, 4, 20)}\n\nhyperpar_selector = RandomizedSearchCV(my_pipeline, par, cv=3, scoring='f1_weighted', n_jobs=1, n_iter=20)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train_sub.shape)\nprint(y_train.shape)\n\nhyperpar_selector.fit(X=x_train_sub, y=y_train)","execution_count":null,"outputs":[{"output_type":"stream","text":"(68616,)\n(68616, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = teste['SENTENCE'].as_matrix()\ny_test = teste['REL TYPE'].as_matrix()\n\ny_test = label_binarize(y_test, classes=df_train['REL TYPE'].unique())\n\nx_test_sub_list = []\n\nfor i, row in df_test.iterrows():\n    pos_t1 = row['SENTENCE'].find(row['ENTITY1'])\n    pos_t2 = row['SENTENCE'].find(row['ENTITY2'])    \n\n    if pos_t1 < pos_t2:\n        len_t1 = len(row['ENTITY1'])    \n        x_test_sub_list.append(row['SENTENCE'][pos_t1+len_t1:pos_t2])\n    else:\n        len_t2 = len(row['ENTITY2'])    \n        x_test_sub_list.append(row['SENTENCE'][pos_t2+len_t2:pos_t1])\n    \n\nx_test_sub = np.array(x_test_sub_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predicted = hyperpar_selector.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_predicted, target_names=treino['REL TYPE'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}