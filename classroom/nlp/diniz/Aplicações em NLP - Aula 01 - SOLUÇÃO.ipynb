{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "918b69ea872adc5e949dd25435d2fc22149d389f"
   },
   "source": [
    "<h1 align=\"center\"> Aplicações em Processamento de Linguagem Natural </h1>\n",
    "<h2 align=\"center\"> Aula 01 - Introdução ao Processamento de Linguagem Natural</h2>\n",
    "<h3 align=\"center\"> Prof. Fernando Vieira da Silva MSc.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "<h2>O que é Processamento de Linguagem Natural? (Natural Language Processing - NLP)</h2>\n",
    "\n",
    "<p>É um subcampo da Ciência da Computação e Inteligência Artificial. Reune uma série de técnicas empregadas na compreensão e geração automática de texto.\n",
    "</p>\n",
    "\n",
    "<p>No princípio, aplicações em NLP eram criadas com base em regras codificadas (hard-coded), geralmente extraídas de conhecimento linguístico. Mas, com o advento de modernas técnicas de Aprendizado e Máquina - e, mais recentemente, Aprendizado Profundo (Deep Learning) - essas técnicas se tornaram mais comuns em aplicações atuais. Ao longo desse curso, vamos estudar essas técnicas que estão em mais evidência nos dias atuais.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fc87443102ebb1df86484d08c90cc8a7ed66127"
   },
   "source": [
    "<h2>Tipos de aplicações de NLP</h2>\n",
    "\n",
    "* Sistemas de recomendação de texto\n",
    "* Sistemas de respostas automáticas (ex: chatbots)\n",
    "* Sistemas de sumarização automática\n",
    "* Sistemas de classificação de sentimentos\n",
    "* Tradutores automáticos\n",
    "* Corretores ortográficos\n",
    "* etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4558b503c8a1590baf9c9a44d30f2bc83a5d8848"
   },
   "source": [
    "<h2>O que é um corpus?</h2>\n",
    "\n",
    "<p>É um conjunto de textos escritos em um determinado idioma, geralmente anotados de alguma forma (ex: anotações sintáticas, sentimentos, etc). Um conjunto de corpus é chamado de corpora.\n",
    "</p>\n",
    "<p>Podemos acessar diversos corpora disponíveis no NLTK (Natural Language Tool Kit). Exemplos:</p>\n",
    "* **Corpus Gutenberg** - coleção com diversos livros gratuitos (o NLTK disponibiliza alguns deles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "74c0e19991a9c21424bda8a5353ce1a62f11f862"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f1f768a6d98ae3228909ac412c717a3847aed55"
   },
   "outputs": [],
   "source": [
    "nltk.corpus.gutenberg.raw(\"shakespeare-hamlet.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f6e8f150dd98bd26b5df6ed9bdaab7a3fda72a21"
   },
   "source": [
    "* **Corpus Machado** - Divesas obras de Machado de Assis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5babfdf8eb66d6bb010cc94866023180a6a210a9"
   },
   "outputs": [],
   "source": [
    "nltk.corpus.machado.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f05934c3af20ecc9e9c25fbbdf7cdf1beb7a62bc"
   },
   "outputs": [],
   "source": [
    "nltk.corpus.machado.raw(\"contos/macn001.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f9bb338bae08438c2fef3cd98a2316572eccfa9a"
   },
   "source": [
    "* **Corpus NPS** - Chat de conteúdo adulto, criado originalmente para identificar predadores sexuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f9461861a9a414e5226a5c555209b716bbca9a2"
   },
   "outputs": [],
   "source": [
    "nltk.corpus.nps_chat.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "960327623fc1a1eb677d49863ccb3a1ca324a017"
   },
   "outputs": [],
   "source": [
    "nltk.corpus.nps_chat.posts(\"11-06-adults_706posts.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1f8a4f9cefec9184edbb0817d4abe135a77117ba"
   },
   "source": [
    "* **Corpus Brown** - Corpus com textos de 500 fontes diferentes, categorizados por gênero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "faf1c89a10a9b313bdc2076b81c42031c3dc3a2c"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "210e7194f987bf4ec3343459d6fa2df10b0bd453"
   },
   "outputs": [],
   "source": [
    "brown.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f54f4a14551b0522ad5c1da0f1e5f557e8f0a2d7"
   },
   "source": [
    "<h2>Part of Speech Tagging (POS)</h2>\n",
    "\n",
    "<p>POS tagging é a tarefa de anotar palavras de acordo com sua classificação gramatical ou de acordo com sua função no discurso.</p>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col width=\"11%\">\n",
    "<col width=\"27%\">\n",
    "<col width=\"62%\">\n",
    "</colgroup>\n",
    "<thead valign=\"bottom\">\n",
    "<tr><th class=\"head\">Tag</th>\n",
    "<th class=\"head\">Meaning</th>\n",
    "<th class=\"head\">English Examples</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody valign=\"top\">\n",
    "<tr><td><tt class=\"doctest\"><span class=\"pre\">ADJ</span></tt></td>\n",
    "<td>adjective</td>\n",
    "<td><span class=\"example\">new, good, high, special, big, local</span></td>\n",
    "</tr>\n",
    "<tr><td><tt class=\"doctest\"><span class=\"pre\">ADP</span></tt></td>\n",
    "<td>adposition</td>\n",
    "<td><span class=\"example\">on, of, at, with, by, into, under</span></td>\n",
    "</tr>\n",
    "<tr><td><tt class=\"doctest\"><span class=\"pre\">ADV</span></tt></td>\n",
    "<td>adverb</td>\n",
    "<td><span class=\"example\">really, already, still, early, now</span></td>\n",
    "</tr>\n",
    "<tr><td><tt class=\"doctest\"><span class=\"pre\">CONJ</span></tt></td>\n",
    "<td>conjunction</td>\n",
    "<td><span class=\"example\">and, or, but, if, while, although</span></td>\n",
    "</tr>\n",
    "<tr><td><tt class=\"doctest\"><span class=\"pre\">DET</span></tt></td>\n",
    "<td>determiner, article</td>\n",
    "<td><span class=\"example\">the, a, some, most, every, no, which</span></td>\n",
    "</tr>\n",
    "<tr><td><tt class=\"doctest\"><span class=\"pre\">NOUN</span></tt></td>\n",
    "<td>noun</td>\n",
    "<td><span class=\"example\">year, home, costs, time, Africa</span></td>\n",
    "</tr>\n",
    "<tr><td><tt class=\"doctest\"><span class=\"pre\">NUM</span></tt></td>\n",
    "<td>numeral</td>\n",
    "<td><span class=\"example\">twenty-four, fourth, 1991, 14:24</span></td>\n",
    "</tr>\n",
    "<tr><td><tt class=\"doctest\"><span class=\"pre\">PRT</span></tt></td>\n",
    "<td>particle</td>\n",
    "<td><span class=\"example\">at, on, out, over per, that, up, with</span></td>\n",
    "</tr>\n",
    "<tr><td><tt class=\"doctest\"><span class=\"pre\">PRON</span></tt></td>\n",
    "<td>pronoun</td>\n",
    "<td><span class=\"example\">he, their, her, its, my, I, us</span></td>\n",
    "</tr>\n",
    "<tr><td><tt class=\"doctest\"><span class=\"pre\">VERB</span></tt></td>\n",
    "<td>verb</td>\n",
    "<td><span class=\"example\">is, say, told, given, playing, would</span></td>\n",
    "</tr>\n",
    "<tr><td><tt class=\"doctest\"><span class=\"pre\">.</span></tt></td>\n",
    "<td>punctuation marks</td>\n",
    "<td><span class=\"example\">. , ; !</span></td>\n",
    "</tr>\n",
    "<tr><td><tt class=\"doctest\"><span class=\"pre\">X</span></tt></td>\n",
    "<td>other</td>\n",
    "<td><span class=\"example\">ersatz, esprit, dunno, gr8, univeristy</span></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<p fontsize=8>Fonte: https://www.nltk.org/book/ch05.html</p>\n",
    "\n",
    "<p>Porém, há ambiguidade! Exemplos:</p>\n",
    "* Inglês: He will race (VERB) the car. When will the race (NOUN) start?\n",
    "* Português: Eles não vão (VERB) trabalhar hoje para estudar para a prova. Espero que não seja em vão (ADV).\n",
    "\n",
    "<p>Por isso, normalmente os POS Taggers são modelos de Aprendizado de Máquia treinados com atributos como:</p>\n",
    "* Palavra anterior\n",
    "* Palavra seguinte\n",
    "* Indicador se a palavra tem a primeira letra maiúscula.\n",
    "\n",
    "Para o inglês, vamos utilizar um POS Tagger pronto disponível no NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e7f4706cdc8efc81e74b9cf5d5674a6cebd63ed"
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "words = \"He will race the car. When will the race start?\".split(\" \")\n",
    "\n",
    "pos_tags = pos_tag(words)\n",
    "\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b6031b0db7ad7d8753f57bb6b3ac6d8d6254b9c"
   },
   "source": [
    "<p>Porém, não temos um POS Tagger disponível para o Português. Vamos utilizar o modelo disponível na biblioteca Spacy</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "574f86a599b8f6a2292234233d1af1b8cbb5a355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.0.0/pt_core_news_sm-2.0.0.tar.gz#egg=pt_core_news_sm==2.0.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.0.0/pt_core_news_sm-2.0.0.tar.gz (38.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 38.7MB 101.8MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
      "  Running setup.py install for pt-core-news-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed pt-core-news-sm-2.0.0\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /opt/conda/lib/python3.6/site-packages/pt_core_news_sm -->\n",
      "    /opt/conda/lib/python3.6/site-packages/spacy/data/pt_core_news_sm\n",
      "\n",
      "    You can now load the model via spacy.load('pt_core_news_sm')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "506955c50dd1c197c9e94c2f8140c074549c829e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eles PRON\n",
      "não ADV\n",
      "vão AUX\n",
      "trabalhar VERB\n",
      "hoje ADV\n",
      "para ADP\n",
      "estudar VERB\n",
      "para ADP\n",
      "a DET\n",
      "prova NOUN\n",
      ". PUNCT\n",
      "Espero VERB\n",
      "que SCONJ\n",
      "não ADV\n",
      "seja VERB\n",
      "em ADP\n",
      "vão VERB\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.lang.pt import Portuguese\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "tokens = nlp(\"Eles não vão trabalhar hoje para estudar para a prova. Espero que não seja em vão\")\n",
    "for t in tokens:\n",
    "    print(t.text, t.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c2089dfba690a984879e6497501e449e6737cca"
   },
   "source": [
    "<h2>WordNet</h2>\n",
    "\n",
    "<p>WordNet é uma base de palavras associadas a seus sinônimos (chamados <i>synsets</i>).\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "fc5d2a743251a423db0dde062398af875766f98a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "wn.synsets('dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d07e9c8d3e3cce2391322d68cbea3257c962090"
   },
   "source": [
    "<p>Pode-se obter os sinônimos de um POS específico</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc147fb0c6f235ff101f9bbe049e7c3909d544a4"
   },
   "outputs": [],
   "source": [
    "wn.synsets('dog', pos=wn.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "691a5b9d4ce554dac831b2014857253a7afa3ff8"
   },
   "source": [
    "<p>Também pode-se obter definição e exemplo de aplicação em frase</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a4bd2610be31124478bf2d7dd8e3724af9d1363"
   },
   "outputs": [],
   "source": [
    "wn.synset('dog.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "12c01abc55197bf36313698928b56b9b0c777f2b"
   },
   "outputs": [],
   "source": [
    "wn.synset('dog.n.01').examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f4f9f2fad1ea31cc49369bb9b1ac2d7081b198f"
   },
   "source": [
    "<p>O WordNet também conta com palavras em idiomas diferentes. A busca pelos synsets também pode ser feita por palavra e idioma</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51c1086cdaeba393cdde3a3b308792050d6accc1"
   },
   "outputs": [],
   "source": [
    "wn.synset('dog.n.01').lemma_names('por')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "63e43836a653d716e4ffe2d94df719b1f014f2af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canine.n.02'),\n",
       " Synset('bitch.n.04'),\n",
       " Synset('dog.n.01'),\n",
       " Synset('devil.n.02')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('cão', lang='por')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8cab2110532b2311962f782294d29feea6d305ff"
   },
   "source": [
    "<p>Synsets estão associados de acordo com relações semânticas</p>\n",
    "\n",
    "* **Hiperônimo** - Canino é hiperônimo de Cachorro.\n",
    "* **Hipônimo** - Cão de caça é hipônimo de Cachorro, assim como Cachorro é Hipônimo de Canino.\n",
    "* **Holonímia** - Cão é holónimo de pata e focinho.\n",
    "\n",
    "<p><a href=\"https://commons.wikimedia.org/wiki/File:Hyponym_and_hypernym.svg#/media/File:Hyponym_and_hypernym.svg\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b4/Hyponym_and_hypernym.svg\" alt=\"Hyponym and hypernym.svg\" width=\"220\" height=\"90\"></a><br>By Own work - Derived from <a href=\"https://en.wikipedia.org/wiki/File:Hyponymsandhypernyms.jpg\" class=\"extiw\" title=\"en:File:Hyponymsandhypernyms.jpg\">en:File:Hyponymsandhypernyms.jpg</a> by <a href=\"//commons.wikimedia.org/w/index.php?title=User:Tanzx30&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"User:Tanzx30 (page does not exist)\">user:Tanzx30</a> published under CC0 1.0, <a href=\"http://creativecommons.org/publicdomain/zero/1.0/deed.en\" title=\"Creative Commons Zero, Public Domain Dedication\">CC0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=55191814\">Link</a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9db6594cdd9ed30c2e34dceb5150dc83edcc874c"
   },
   "outputs": [],
   "source": [
    "print(\"Hypernyms:\")\n",
    "print(wn.synset('dog.n.01').hypernyms())\n",
    "\n",
    "print(\"Hyponyms:\")\n",
    "print(wn.synset('dog.n.01').hyponyms())\n",
    "\n",
    "print(\"Holonyms\")\n",
    "print(wn.synset('dog.n.01').member_holonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9cbd70c0fef7eee8fff35973f883da3a75a8cc87",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Hypernyms:\")\n",
    "print(wn.synset('canine.n.02').lemma_names())\n",
    "\n",
    "print(\"Hyponyms:\")\n",
    "print(wn.synset('hunting_dog.n.01').lemma_names())\n",
    "\n",
    "print(\"Holonyms\")\n",
    "print(wn.synset('canis.n.01').lemma_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6aed8ea938c8036b9438e5e699739ea19316f23d"
   },
   "source": [
    "<p>Por fim, pode-se obter a similaridade de duas palavras, por meio da distância de menor caminho no grafo de conexões semânticas.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a46c0af1e2cde009f99cc19a19b2fe2f17a5c7c2"
   },
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "fork = wn.synset('fork.n.01')\n",
    "print(dog.path_similarity(cat))\n",
    "print(dog.path_similarity(fork))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b2f5c29e3fbc065fbdea7d8ebff98ca5ae60d72"
   },
   "source": [
    "<p><b>Exercício 1:</b> \n",
    "   Escreva um algoritmo que recebe uma frase em português e mostra as traduções das palavras em Inglês, considerando todos os sinônimos possíveis. Se não encontrar alguma palavra, deve mostrar a palavra em Português.</p>\n",
    "   \n",
    "   Exemplo:\n",
    "   sent = \"O menino bebe café com leite toda manhã\"\n",
    "   \n",
    "   resultado:\n",
    "   [['lordship', 'O', 'o'],\n",
    " ['baby',\n",
    "  'babe',\n",
    "  'infant',\n",
    "  'cub',\n",
    "  'lad',\n",
    "  'laddie',\n",
    "  'sonny',\n",
    "  'sonny_boy',\n",
    "  'chap',\n",
    "  'fellow',\n",
    "  'feller',\n",
    "  'fella',\n",
    "  'lad',\n",
    "  'gent',\n",
    "  'blighter',\n",
    "  'cuss',\n",
    "  'bloke',\n",
    "  'child',\n",
    "  'kid',\n",
    "  'youngster',\n",
    "  'minor',\n",
    "  'shaver',\n",
    "  'nipper',\n",
    "  'small_fry',\n",
    "  'tiddler',\n",
    "  'tike',\n",
    "  'tyke',\n",
    "  'fry',\n",
    "  'nestling',\n",
    "  'child',\n",
    "  'kid',\n",
    "  'child',\n",
    "  'baby',\n",
    "  'daughter',\n",
    "  'girl',\n",
    "  'male_child',\n",
    "  'boy',\n",
    "  'male_offspring',\n",
    "  'man-child',\n",
    "  'son',\n",
    "  'boy'],\n",
    " ['bebe'],\n",
    " ['cafe',\n",
    "  'coffeehouse',\n",
    "  'coffee_shop',\n",
    "  'coffee_bar',\n",
    "  'coffee_break',\n",
    "  'tea_break',\n",
    "  'espresso',\n",
    "  'coffee_bean',\n",
    "  'coffee_berry',\n",
    "  'coffee',\n",
    "  'coffee',\n",
    "  'java',\n",
    "  'coffee',\n",
    "  'java',\n",
    "  'coffee',\n",
    "  'coffee_tree'],\n",
    " ['successfully', 'aboard', 'alongside', 'shoehorn'],\n",
    " ['milk', 'milk', 'milk', \"cows'_milk\"],\n",
    " ['toda'],\n",
    " ['morrow', 'morning', 'morn', 'morning_time', 'forenoon']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "dc8b05e22ac4a390f9381f8993efcb8e87255fda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['lordship', 'O', 'o'],\n",
      " ['baby',\n",
      "  'babe',\n",
      "  'infant',\n",
      "  'cub',\n",
      "  'lad',\n",
      "  'laddie',\n",
      "  'sonny',\n",
      "  'sonny_boy',\n",
      "  'chap',\n",
      "  'fellow',\n",
      "  'feller',\n",
      "  'fella',\n",
      "  'lad',\n",
      "  'gent',\n",
      "  'blighter',\n",
      "  'cuss',\n",
      "  'bloke',\n",
      "  'child',\n",
      "  'kid',\n",
      "  'youngster',\n",
      "  'minor',\n",
      "  'shaver',\n",
      "  'nipper',\n",
      "  'small_fry',\n",
      "  'tiddler',\n",
      "  'tike',\n",
      "  'tyke',\n",
      "  'fry',\n",
      "  'nestling',\n",
      "  'child',\n",
      "  'kid',\n",
      "  'child',\n",
      "  'baby',\n",
      "  'daughter',\n",
      "  'girl',\n",
      "  'male_child',\n",
      "  'boy',\n",
      "  'male_offspring',\n",
      "  'man-child',\n",
      "  'son',\n",
      "  'boy'],\n",
      " ['bebe'],\n",
      " ['cafe',\n",
      "  'coffeehouse',\n",
      "  'coffee_shop',\n",
      "  'coffee_bar',\n",
      "  'coffee_break',\n",
      "  'tea_break',\n",
      "  'espresso',\n",
      "  'coffee_bean',\n",
      "  'coffee_berry',\n",
      "  'coffee',\n",
      "  'coffee',\n",
      "  'java',\n",
      "  'coffee',\n",
      "  'java',\n",
      "  'coffee',\n",
      "  'coffee_tree'],\n",
      " ['successfully', 'aboard', 'alongside', 'shoehorn'],\n",
      " ['milk', 'milk', 'milk', \"cows'_milk\"],\n",
      " ['toda'],\n",
      " ['morrow', 'morning', 'morn', 'morning_time', 'forenoon']]\n"
     ]
    }
   ],
   "source": [
    "sent = \"O menino bebe café com leite toda manhã\"\n",
    "\n",
    "import spacy\n",
    "import pprint\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from spacy.lang.pt import Portuguese\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "tokens = nlp(sent)\n",
    "    \n",
    "results = [[] for i in range(len(tokens))]\n",
    "wn_pos = {'NOUN':wn.NOUN, 'ADJ':wn.ADJ,\n",
    "                  'VERB':wn.VERB, 'ADV':wn.ADV}\n",
    "for i in range(len(tokens)):\n",
    "    t = tokens[i]    \n",
    "    if not t.pos_ in wn_pos.keys():\n",
    "        syns = wn.synsets(t.text, lang='por')\n",
    "    else:\n",
    "        syns = wn.synsets(t.text, lang='por', pos=wn_pos[t.pos_])\n",
    "        \n",
    "    if len(syns) == 0:\n",
    "        results[i].append(t.text)\n",
    "    else:\n",
    "        for s in syns:\n",
    "            results[i].extend(s.lemma_names())\n",
    "            \n",
    "pprint.pprint(results)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3aeedb901592234b0dff70718960270602d00a75"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
