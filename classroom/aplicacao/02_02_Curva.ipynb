{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como gerar curvas de aprendizagem\n",
    "\n",
    "Uma ferramenta de diagnóstico bastante importante para quem trabalha com ciência dos dados, especificamente com aprendizado de máquina, são as curvas de aprendizagem. Elas trazem detalhes de evolução do modelo com relação à exposição de novas amostras e como se comporta o desempenho do conjunto de teste fixo.\n",
    "\n",
    "---\n",
    "\n",
    "O conjunto de dados a ser utilizado será idêntico ao da primeira parte desse encontro. Novamente os dados serão carregados e organizados em uma variável de atributo e uma de rótulo, X e y, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('energy_data.csv')\n",
    "df.describe()\n",
    "\n",
    "X = df.drop(['Appliances','date'],axis=1)\n",
    "y = df.Appliances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A curva de aprendizagem pode ser obtida ao executar consecutivamente o ajuste de um modelo a um número progressivo de amostras de treino, medindo seu desempenho contra um conjunto de teste de tamanho fixo. Ao final, é possível utilizar essas informações para verificar como acontece a aprendizagem do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "n_amostras = list(range(1, X_train.shape[0], int(X_train.shape[0]/50)))\n",
    "resultados_treino = []\n",
    "resultados_teste  = []\n",
    "\n",
    "# suponha dividir todos os dados em 10 partes\n",
    "for i in n_amostras:\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X_train[:i], y_train[:i])\n",
    "    resultados_treino.append(metrics.mean_squared_error(model.predict(X_train[:i]), y_train[:i]))\n",
    "    resultados_teste.append(metrics.mean_squared_error(model.predict(X_test), y_test))\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(n_amostras, resultados_treino, 'o-', color=\"r\", label=\"Treino\")\n",
    "plt.plot(n_amostras, resultados_teste, 'o-', color=\"b\", label=\"Teste\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse gráfico é possível observar alguns aspectos importantes:\n",
    "1. No primeiro instante, o treino não tem erro nenhum, e o teste tem um erro altíssimo. Isso é esperado porque o modelo foi treinado com uma ou pouquíssimas amostras, e tem que acertar somente essa pequena quantidade.\n",
    "2. Rapidamente, o erro cai do teste porque o modelo está generalizando, enquanto o erro do treino sobe porque está aumentando o número de amostras que faz parte da avaliação agora.\n",
    "3. Em seguida, o erro do treino começa diminuir consideravelmente, mas o erro do teste segue descendo bem pouco.\n",
    "\n",
    "Esse cenário não é ruim, mas é importante se **questionar se esse erro estacionário próximo a 8k não é muito alto**, e observar **se a tendência da curva não é o erro de teste começar a subir**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativo a fazer todo o processo manualmente, a função *learning_curve* auxilia a executar o processo de encontrar os diferentes valores de erro para diferentes tamanhos de amostras de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import linear_model\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,\n",
    "        scoring='neg_mean_squared_error')\n",
    "    train_scores_mean = np.mean(train_scores, axis=1) * -1\n",
    "    train_scores_std = np.std(train_scores, axis=1) * -1\n",
    "    test_scores_mean = np.mean(test_scores, axis=1) * -1\n",
    "    test_scores_std = np.std(test_scores, axis=1) * -1\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Treino\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Teste\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "title = \"Curva de Aprendizagem\"\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = linear_model.Lasso(alpha=2.5)\n",
    "plot_learning_curve(estimator, title, X, y, cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados são suavizados com cross-validation no exemplo anterior e é possível perceber uma sobreposição da região verde com a vermelha quase ao final da curva. Quando isso acontece, pode ser interessante parar o treinamento antes ou mudar o modelo para algum outro que não sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios\n",
    "\n",
    "1. **Analise a curva de aprendizagem para as melhores configurações encontradas nos exercícios do notebook anterior.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
